{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ChatBot.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Yn9lnpTUmcN"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gensim\n",
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O13IG_UyAb4E",
        "outputId": "53d8fea2-11a9-42e3-9a21-e10e264e6ea6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_uPQEbYQmC_"
      },
      "source": [
        "df = pd.read_csv('/content/drive/My Drive/DataSet/cleaned.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkv4jILYRTAq"
      },
      "source": [
        "df_copy = df.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jl5tV4W4Rhne",
        "outputId": "f0c09c9b-e26b-474e-b48b-395658652fbc"
      },
      "source": [
        "df_copy.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6071, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "pczJpZD6Rkoc",
        "outputId": "06aea218-62ff-46b0-e336-2e8f59ec444a"
      },
      "source": [
        "df_copy.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>questions</th>\n",
              "      <th>Answers</th>\n",
              "      <th>Unnamed: 2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>How is the write?</td>\n",
              "      <td>excellent writing</td>\n",
              "      <td>Books</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What impact did the book have?</td>\n",
              "      <td>It 's just a shame that what the book had to o...</td>\n",
              "      <td>Books</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Is the plot line good enough?</td>\n",
              "      <td>The book got me hooked almost immediately Char...</td>\n",
              "      <td>Books</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Which is the good premise principal?</td>\n",
              "      <td>premise is interesting</td>\n",
              "      <td>Books</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>How is the book?</td>\n",
              "      <td>The escapee turns out to be Sirius Black the</td>\n",
              "      <td>Books</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                              questions  ... Unnamed: 2\n",
              "0                     How is the write?  ...      Books\n",
              "1        What impact did the book have?  ...      Books\n",
              "2         Is the plot line good enough?  ...      Books\n",
              "3  Which is the good premise principal?  ...      Books\n",
              "4                      How is the book?  ...      Books\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2lSLA0e8RqXD"
      },
      "source": [
        "df_copy = df_copy.rename(columns = {\"Unnamed: 2\" : \"Y\"})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "haMJYIuAZ3Pm",
        "outputId": "479e6eec-8b48-49f5-96d7-2eb8875de76b"
      },
      "source": [
        "df_copy.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>questions</th>\n",
              "      <th>Answers</th>\n",
              "      <th>Y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>How is the write?</td>\n",
              "      <td>excellent writing</td>\n",
              "      <td>Books</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What impact did the book have?</td>\n",
              "      <td>It 's just a shame that what the book had to o...</td>\n",
              "      <td>Books</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Is the plot line good enough?</td>\n",
              "      <td>The book got me hooked almost immediately Char...</td>\n",
              "      <td>Books</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Which is the good premise principal?</td>\n",
              "      <td>premise is interesting</td>\n",
              "      <td>Books</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>How is the book?</td>\n",
              "      <td>The escapee turns out to be Sirius Black the</td>\n",
              "      <td>Books</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                              questions  ...      Y\n",
              "0                     How is the write?  ...  Books\n",
              "1        What impact did the book have?  ...  Books\n",
              "2         Is the plot line good enough?  ...  Books\n",
              "3  Which is the good premise principal?  ...  Books\n",
              "4                      How is the book?  ...  Books\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvWnrRGuPpyu"
      },
      "source": [
        "df_copy['questions'] = df_copy['questions'].str.lower()\n",
        "df_copy['questions'] = df_copy['questions'].str.replace(\"?\", \"\")\n",
        "df_copy['tokanized'] = df_copy['questions'].apply(lambda x: x.split(' '))\n",
        "stop_words = [\"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\", \"itself\", \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\", \"those\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\", \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \"should\", \"now\"]\n",
        "df_copy['tokanized'] = df_copy['tokanized'].apply(lambda x: [item for item in x if item not in stop_words])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "h_tha3kuP5m0",
        "outputId": "ea8c6102-737b-44fc-a357-1832ee446f89"
      },
      "source": [
        "df_copy.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>questions</th>\n",
              "      <th>Answers</th>\n",
              "      <th>Y</th>\n",
              "      <th>tokanized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>how is the write</td>\n",
              "      <td>excellent writing</td>\n",
              "      <td>Books</td>\n",
              "      <td>[write]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>what impact did the book have</td>\n",
              "      <td>It 's just a shame that what the book had to o...</td>\n",
              "      <td>Books</td>\n",
              "      <td>[impact, book]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>is the plot line good enough</td>\n",
              "      <td>The book got me hooked almost immediately Char...</td>\n",
              "      <td>Books</td>\n",
              "      <td>[plot, line, good, enough]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>which is the good premise principal</td>\n",
              "      <td>premise is interesting</td>\n",
              "      <td>Books</td>\n",
              "      <td>[good, premise, principal]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>how is the book</td>\n",
              "      <td>The escapee turns out to be Sirius Black the</td>\n",
              "      <td>Books</td>\n",
              "      <td>[book]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                             questions  ...                   tokanized\n",
              "0                     how is the write  ...                     [write]\n",
              "1        what impact did the book have  ...              [impact, book]\n",
              "2         is the plot line good enough  ...  [plot, line, good, enough]\n",
              "3  which is the good premise principal  ...  [good, premise, principal]\n",
              "4                      how is the book  ...                      [book]\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDSfJx21TkI-",
        "outputId": "db3f576e-1d8b-4332-b258-a39414fc6c76"
      },
      "source": [
        "df_copy.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "questions    0\n",
              "Answers      0\n",
              "Y            0\n",
              "tokanized    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4uQWZmmDJA9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96cd533a-063a-46be-fac6-063975cb6714"
      },
      "source": [
        "# data_questions = df_copy['tokanized'].apply(lambda x: [x]).tolist() \n",
        "data_questions = np.asarray(df_copy['tokanized'])\n",
        "data_questions"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([list(['write']), list(['impact', 'book']),\n",
              "       list(['plot', 'line', 'good', 'enough']), ..., list(['hotel']),\n",
              "       list(['parking']), list(['stay'])], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZgV9sfDUpni",
        "outputId": "77b0030c-35e1-4a08-88da-50634d5e3a25"
      },
      "source": [
        "df_copy['tokanized'].dtypes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('O')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3239g6ieFqkg",
        "outputId": "9b7022e6-bd61-425b-edea-3bdd9ab4b96e"
      },
      "source": [
        "def tagged_document(list_of_list_of_words):\n",
        "   for i, list_of_words in enumerate(list_of_list_of_words):\n",
        "      yield gensim.models.doc2vec.TaggedDocument(list_of_words, [i])\n",
        "data_for_training_questions = list(tagged_document(data_questions))\n",
        "print(data_for_training_questions[:1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[TaggedDocument(words=['write'], tags=[0])]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CN69477zWMKY"
      },
      "source": [
        "model_questions = gensim.models.doc2vec.Doc2Vec(vector_size=40, min_count=1, epochs=30)\n",
        "model_questions.build_vocab(data_for_training_questions)\n",
        "model_questions.train(data_for_training_questions, total_examples=model_questions.corpus_count, epochs=model_questions.epochs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mqs1rJwBcTml",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15229bc0-f5d1-4a6c-dc1a-2dfe48fda8dd"
      },
      "source": [
        "# data_answers = df_copy.Answers.values.tolist()\n",
        "data_answers = df_copy['Answers'].apply(lambda x: [x]).tolist() \n",
        "data_answers = np.asarray(data_answers)\n",
        "data_answers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['excellent writing'],\n",
              "       [\"It 's just a shame that what the book had to offer was no surprise to me\"],\n",
              "       ['The book got me hooked almost immediately Characters and dialogue are good but I liked the movie better'],\n",
              "       ...,\n",
              "       ['this upscale hotel is highly recommended and its location is hard to beat'],\n",
              "       ['The parking rate is ridiculously high'],\n",
              "       ['The Hotel Adagio is absolutely FABULOUS']], dtype='<U429')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OEexSEJMeQpA",
        "outputId": "9d7a62b9-42c1-4d32-d5b5-da3f60f0e8de"
      },
      "source": [
        "def tagged_document(list_of_list_of_words):\n",
        "   for i, list_of_words in enumerate(list_of_list_of_words):\n",
        "      yield gensim.models.doc2vec.TaggedDocument(list_of_words, [i])\n",
        "data_for_training_answers = list(tagged_document(data_answers))\n",
        "print(data_for_training_answers[:1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[TaggedDocument(words=array(['excellent writing'], dtype='<U429'), tags=[0])]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hC2Q7rvQecUL"
      },
      "source": [
        "model_answers = gensim.models.doc2vec.Doc2Vec(vector_size=40, min_count=2, epochs=30)\n",
        "model_answers.build_vocab(data_for_training_answers)\n",
        "model_answers.train(data_for_training_answers, total_examples=model_answers.corpus_count, epochs=model_answers.epochs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Nt18yqqQ5Lv",
        "outputId": "eb009ffe-2901-49c3-c236-f23035e5f82b"
      },
      "source": [
        "answer1 = model_answers.infer_vector(['excellent', 'writing'])\n",
        "answer1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.00358992,  0.01163803,  0.00492914,  0.00492813,  0.00619977,\n",
              "       -0.0047428 , -0.01113535,  0.00769555, -0.00433497, -0.00966512,\n",
              "       -0.00595968, -0.00556116, -0.00633477, -0.00981487, -0.00616774,\n",
              "       -0.01177523, -0.01175572,  0.00687055,  0.00611734, -0.00607264,\n",
              "        0.01188127, -0.0020296 ,  0.00157827, -0.00193782, -0.01222141,\n",
              "       -0.00309405, -0.00805303,  0.01073469, -0.00129026,  0.01259939,\n",
              "        0.00621524,  0.00783388, -0.00874103,  0.00928554, -0.00185307,\n",
              "       -0.00817985, -0.0063961 ,  0.00383142,  0.01172819,  0.00499512],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5VF2UUJpPcbI",
        "outputId": "78b8e0f3-c6a5-42bc-b6cd-62c24a33c03e"
      },
      "source": [
        "df_copy['tokanized']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                                [write]\n",
              "1                         [impact, book]\n",
              "2             [plot, line, good, enough]\n",
              "3             [good, premise, principal]\n",
              "4                                 [book]\n",
              "                      ...               \n",
              "6066    [provide, variety, fresh, fruit]\n",
              "6067          [company, great, security]\n",
              "6068                             [hotel]\n",
              "6069                           [parking]\n",
              "6070                              [stay]\n",
              "Name: tokanized, Length: 6071, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upmgnbO7VAoh"
      },
      "source": [
        "text_questions = []\n",
        "text1 =\"\"\n",
        "for i in range(0, (len(df_copy))):\n",
        "  text1 = model_questions.infer_vector(df_copy['tokanized'][i])\n",
        "  text_questions.append(text1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AsUnhwUDVsv_",
        "outputId": "53049d74-ad24-4782-997a-934d38baf9b6"
      },
      "source": [
        "text_questions[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.11424679, -0.05039364, -0.02274443, -0.11224426, -0.02521368,\n",
              "        0.02848174,  0.07204197, -0.05895597,  0.12337315, -0.05156697,\n",
              "       -0.03156791,  0.0104045 ,  0.04283414,  0.08917993,  0.02597294,\n",
              "       -0.05183435,  0.07645292,  0.01934693, -0.0039937 , -0.00864717,\n",
              "       -0.01387371,  0.02897566, -0.05878798, -0.12757567,  0.01895954,\n",
              "       -0.0188218 ,  0.06629013,  0.07236961,  0.11753877, -0.00521357,\n",
              "        0.06813588,  0.01992505, -0.03972434, -0.01539173, -0.08297485,\n",
              "        0.02261083,  0.01194965, -0.05576629, -0.02114967,  0.02189767],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AH8RGV2sZuA2",
        "outputId": "b0470cb7-abc1-4027-aa92-b3165cfe0a2b"
      },
      "source": [
        "data_y = np.asarray(df_copy.Y)\n",
        "data_y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Books', 'Books', 'Books', ..., 'tripadvisor', 'tripadvisor',\n",
              "       'tripadvisor'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPX9ewJEib0S"
      },
      "source": [
        "text_questions = np.stack([i.tolist() for i in text_questions])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwwsgQvhuxSH"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(df_copy.Y)\n",
        "y_train = encoder.transform(df_copy.Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OuUERlQXapjS",
        "outputId": "fda4c595-15ee-4b1e-d295-b5cea6b86ce8"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout\n",
        "model_predict_questions = Sequential()              \n",
        "model_predict_questions.add(Dense(128, input_dim=text_questions.shape[1], activation= 'relu' ))\n",
        "model_predict_questions.add(Dropout(0.4))\n",
        "model_predict_questions.add(Dense(64, activation= 'tanh' ))\n",
        "model_predict_questions.add(Dropout(0.4))\n",
        "model_predict_questions.add(Dense(6, activation='softmax'))\n",
        "model_predict_questions.compile(loss='sparse_categorical_crossentropy',optimizer='adam', metrics=['accuracy'])\n",
        "model_predict_questions.summary()\n",
        "model_predict_questions.fit(text_questions, y_train, epochs=500, verbose=1)\n",
        "scores = model_predict_questions.evaluate(text_questions, y_train)\n",
        "print (scores)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 128)               5248      \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 6)                 390       \n",
            "=================================================================\n",
            "Total params: 13,894\n",
            "Trainable params: 13,894\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/500\n",
            "190/190 [==============================] - 15s 2ms/step - loss: 1.7837 - accuracy: 0.2236\n",
            "Epoch 2/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.7522 - accuracy: 0.2472\n",
            "Epoch 3/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.7353 - accuracy: 0.2604\n",
            "Epoch 4/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.7217 - accuracy: 0.2686\n",
            "Epoch 5/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.7031 - accuracy: 0.2758\n",
            "Epoch 6/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.6929 - accuracy: 0.2738\n",
            "Epoch 7/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.6816 - accuracy: 0.2886\n",
            "Epoch 8/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.6826 - accuracy: 0.3039\n",
            "Epoch 9/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.6552 - accuracy: 0.3095\n",
            "Epoch 10/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.6440 - accuracy: 0.3144\n",
            "Epoch 11/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.6319 - accuracy: 0.3272\n",
            "Epoch 12/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.6169 - accuracy: 0.3243\n",
            "Epoch 13/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.6132 - accuracy: 0.3333\n",
            "Epoch 14/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.6023 - accuracy: 0.3331\n",
            "Epoch 15/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.6008 - accuracy: 0.3390\n",
            "Epoch 16/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.6096 - accuracy: 0.3425\n",
            "Epoch 17/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.6028 - accuracy: 0.3357\n",
            "Epoch 18/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.5892 - accuracy: 0.3445\n",
            "Epoch 19/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.5914 - accuracy: 0.3407\n",
            "Epoch 20/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.5739 - accuracy: 0.3566\n",
            "Epoch 21/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.5539 - accuracy: 0.3661\n",
            "Epoch 22/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.5642 - accuracy: 0.3579\n",
            "Epoch 23/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.5537 - accuracy: 0.3510\n",
            "Epoch 24/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.5467 - accuracy: 0.3698\n",
            "Epoch 25/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.5432 - accuracy: 0.3702\n",
            "Epoch 26/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.5270 - accuracy: 0.3718\n",
            "Epoch 27/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.5181 - accuracy: 0.3768\n",
            "Epoch 28/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.5439 - accuracy: 0.3815\n",
            "Epoch 29/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.5127 - accuracy: 0.3865\n",
            "Epoch 30/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.5281 - accuracy: 0.3792\n",
            "Epoch 31/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.5301 - accuracy: 0.3747\n",
            "Epoch 32/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.4966 - accuracy: 0.3925\n",
            "Epoch 33/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.5238 - accuracy: 0.3791\n",
            "Epoch 34/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.5090 - accuracy: 0.3804\n",
            "Epoch 35/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.5112 - accuracy: 0.3854\n",
            "Epoch 36/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.4947 - accuracy: 0.3879\n",
            "Epoch 37/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.4888 - accuracy: 0.4097\n",
            "Epoch 38/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.4807 - accuracy: 0.3930\n",
            "Epoch 39/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.4707 - accuracy: 0.4031\n",
            "Epoch 40/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.4805 - accuracy: 0.3948\n",
            "Epoch 41/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.4793 - accuracy: 0.3936\n",
            "Epoch 42/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.4681 - accuracy: 0.4118\n",
            "Epoch 43/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.4646 - accuracy: 0.4155\n",
            "Epoch 44/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.4656 - accuracy: 0.4099\n",
            "Epoch 45/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.4711 - accuracy: 0.4015\n",
            "Epoch 46/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.4693 - accuracy: 0.3927\n",
            "Epoch 47/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.4461 - accuracy: 0.4109\n",
            "Epoch 48/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.4478 - accuracy: 0.4275\n",
            "Epoch 49/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.4485 - accuracy: 0.4120\n",
            "Epoch 50/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.4383 - accuracy: 0.4209\n",
            "Epoch 51/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.4115 - accuracy: 0.4306\n",
            "Epoch 52/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.4175 - accuracy: 0.4328\n",
            "Epoch 53/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.4301 - accuracy: 0.4167\n",
            "Epoch 54/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.4263 - accuracy: 0.4328\n",
            "Epoch 55/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.4213 - accuracy: 0.4373\n",
            "Epoch 56/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.4161 - accuracy: 0.4220\n",
            "Epoch 57/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.4212 - accuracy: 0.4328\n",
            "Epoch 58/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.4118 - accuracy: 0.4295\n",
            "Epoch 59/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.4094 - accuracy: 0.4288\n",
            "Epoch 60/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.4046 - accuracy: 0.4428\n",
            "Epoch 61/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.4069 - accuracy: 0.4277\n",
            "Epoch 62/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.3968 - accuracy: 0.4405\n",
            "Epoch 63/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.3964 - accuracy: 0.4458\n",
            "Epoch 64/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.3896 - accuracy: 0.4399\n",
            "Epoch 65/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.3931 - accuracy: 0.4345\n",
            "Epoch 66/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.3940 - accuracy: 0.4420\n",
            "Epoch 67/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.4033 - accuracy: 0.4380\n",
            "Epoch 68/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.3968 - accuracy: 0.4392\n",
            "Epoch 69/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.3815 - accuracy: 0.4404\n",
            "Epoch 70/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.3803 - accuracy: 0.4431\n",
            "Epoch 71/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.3749 - accuracy: 0.4464\n",
            "Epoch 72/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.3760 - accuracy: 0.4443\n",
            "Epoch 73/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.3646 - accuracy: 0.4557\n",
            "Epoch 74/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.3822 - accuracy: 0.4373\n",
            "Epoch 75/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.3644 - accuracy: 0.4538\n",
            "Epoch 76/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.3491 - accuracy: 0.4768\n",
            "Epoch 77/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.3557 - accuracy: 0.4620\n",
            "Epoch 78/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.3469 - accuracy: 0.4592\n",
            "Epoch 79/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.3395 - accuracy: 0.4671\n",
            "Epoch 80/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.3578 - accuracy: 0.4641\n",
            "Epoch 81/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.3433 - accuracy: 0.4523\n",
            "Epoch 82/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.3601 - accuracy: 0.4562\n",
            "Epoch 83/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.3451 - accuracy: 0.4658\n",
            "Epoch 84/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.3631 - accuracy: 0.4567\n",
            "Epoch 85/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.3489 - accuracy: 0.4588\n",
            "Epoch 86/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.3429 - accuracy: 0.4744\n",
            "Epoch 87/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.3387 - accuracy: 0.4648\n",
            "Epoch 88/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.3553 - accuracy: 0.4547\n",
            "Epoch 89/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.3275 - accuracy: 0.4819\n",
            "Epoch 90/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.3301 - accuracy: 0.4642\n",
            "Epoch 91/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.3381 - accuracy: 0.4745\n",
            "Epoch 92/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.3406 - accuracy: 0.4507\n",
            "Epoch 93/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.3267 - accuracy: 0.4699\n",
            "Epoch 94/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.3232 - accuracy: 0.4819\n",
            "Epoch 95/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.3027 - accuracy: 0.4790\n",
            "Epoch 96/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.3099 - accuracy: 0.4776\n",
            "Epoch 97/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.3221 - accuracy: 0.4793\n",
            "Epoch 98/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.3061 - accuracy: 0.4807\n",
            "Epoch 99/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.3002 - accuracy: 0.4765\n",
            "Epoch 100/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.3295 - accuracy: 0.4840\n",
            "Epoch 101/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.3036 - accuracy: 0.4967\n",
            "Epoch 102/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.3038 - accuracy: 0.4901\n",
            "Epoch 103/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.2921 - accuracy: 0.4929\n",
            "Epoch 104/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.3294 - accuracy: 0.4783\n",
            "Epoch 105/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.3258 - accuracy: 0.4768\n",
            "Epoch 106/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.3038 - accuracy: 0.4786\n",
            "Epoch 107/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.2886 - accuracy: 0.4888\n",
            "Epoch 108/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.3016 - accuracy: 0.4847\n",
            "Epoch 109/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.2908 - accuracy: 0.4855\n",
            "Epoch 110/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.3007 - accuracy: 0.4870\n",
            "Epoch 111/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.2771 - accuracy: 0.4963\n",
            "Epoch 112/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.3007 - accuracy: 0.4824\n",
            "Epoch 113/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.2976 - accuracy: 0.4856\n",
            "Epoch 114/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.2855 - accuracy: 0.4923\n",
            "Epoch 115/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.2925 - accuracy: 0.4986\n",
            "Epoch 116/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.2713 - accuracy: 0.5035\n",
            "Epoch 117/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.2985 - accuracy: 0.4883\n",
            "Epoch 118/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.3067 - accuracy: 0.4858\n",
            "Epoch 119/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.2734 - accuracy: 0.5003\n",
            "Epoch 120/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.2860 - accuracy: 0.4946\n",
            "Epoch 121/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.2689 - accuracy: 0.5072\n",
            "Epoch 122/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.2621 - accuracy: 0.4985\n",
            "Epoch 123/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.2684 - accuracy: 0.4948\n",
            "Epoch 124/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.2563 - accuracy: 0.4988\n",
            "Epoch 125/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.2952 - accuracy: 0.4939\n",
            "Epoch 126/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.2755 - accuracy: 0.5065\n",
            "Epoch 127/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.2801 - accuracy: 0.4982\n",
            "Epoch 128/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.2584 - accuracy: 0.5095\n",
            "Epoch 129/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.2591 - accuracy: 0.4993\n",
            "Epoch 130/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.2672 - accuracy: 0.5011\n",
            "Epoch 131/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.2352 - accuracy: 0.5217\n",
            "Epoch 132/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.2794 - accuracy: 0.4977\n",
            "Epoch 133/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.2805 - accuracy: 0.5011\n",
            "Epoch 134/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.2405 - accuracy: 0.5143\n",
            "Epoch 135/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.2339 - accuracy: 0.5150\n",
            "Epoch 136/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.2658 - accuracy: 0.5001\n",
            "Epoch 137/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.2458 - accuracy: 0.5148\n",
            "Epoch 138/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.2432 - accuracy: 0.5170\n",
            "Epoch 139/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.2265 - accuracy: 0.5222\n",
            "Epoch 140/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.2491 - accuracy: 0.5022\n",
            "Epoch 141/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.2327 - accuracy: 0.5164\n",
            "Epoch 142/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.2468 - accuracy: 0.5108\n",
            "Epoch 143/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.2268 - accuracy: 0.5106\n",
            "Epoch 144/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.2400 - accuracy: 0.5147\n",
            "Epoch 145/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.2538 - accuracy: 0.5114\n",
            "Epoch 146/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.2516 - accuracy: 0.5136\n",
            "Epoch 147/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.2136 - accuracy: 0.5280\n",
            "Epoch 148/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.2292 - accuracy: 0.5194\n",
            "Epoch 149/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.2220 - accuracy: 0.5211\n",
            "Epoch 150/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.2385 - accuracy: 0.5079\n",
            "Epoch 151/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.2235 - accuracy: 0.5130\n",
            "Epoch 152/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.2164 - accuracy: 0.5177\n",
            "Epoch 153/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.2484 - accuracy: 0.5078\n",
            "Epoch 154/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.2300 - accuracy: 0.5114\n",
            "Epoch 155/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.2578 - accuracy: 0.5116\n",
            "Epoch 156/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.2183 - accuracy: 0.5275\n",
            "Epoch 157/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.2417 - accuracy: 0.5188\n",
            "Epoch 158/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.2178 - accuracy: 0.5295\n",
            "Epoch 159/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.2364 - accuracy: 0.5158\n",
            "Epoch 160/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.2267 - accuracy: 0.5191\n",
            "Epoch 161/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.2192 - accuracy: 0.5260\n",
            "Epoch 162/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.2067 - accuracy: 0.5243\n",
            "Epoch 163/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.2132 - accuracy: 0.5182\n",
            "Epoch 164/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1813 - accuracy: 0.5399\n",
            "Epoch 165/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.2092 - accuracy: 0.5181\n",
            "Epoch 166/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.2105 - accuracy: 0.5260\n",
            "Epoch 167/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.2270 - accuracy: 0.5135\n",
            "Epoch 168/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1993 - accuracy: 0.5244\n",
            "Epoch 169/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.2084 - accuracy: 0.5250\n",
            "Epoch 170/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.2298 - accuracy: 0.5247\n",
            "Epoch 171/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.2043 - accuracy: 0.5303\n",
            "Epoch 172/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.2443 - accuracy: 0.5080\n",
            "Epoch 173/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1862 - accuracy: 0.5284\n",
            "Epoch 174/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1988 - accuracy: 0.5281\n",
            "Epoch 175/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.2006 - accuracy: 0.5214\n",
            "Epoch 176/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.2010 - accuracy: 0.5239\n",
            "Epoch 177/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.2011 - accuracy: 0.5385\n",
            "Epoch 178/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.2067 - accuracy: 0.5164\n",
            "Epoch 179/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1840 - accuracy: 0.5476\n",
            "Epoch 180/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1760 - accuracy: 0.5427\n",
            "Epoch 181/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.2066 - accuracy: 0.5322\n",
            "Epoch 182/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.2106 - accuracy: 0.5258\n",
            "Epoch 183/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1955 - accuracy: 0.5329\n",
            "Epoch 184/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1775 - accuracy: 0.5415\n",
            "Epoch 185/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1785 - accuracy: 0.5372\n",
            "Epoch 186/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.2041 - accuracy: 0.5324\n",
            "Epoch 187/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1988 - accuracy: 0.5203\n",
            "Epoch 188/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1854 - accuracy: 0.5380\n",
            "Epoch 189/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.2006 - accuracy: 0.5373\n",
            "Epoch 190/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1782 - accuracy: 0.5397\n",
            "Epoch 191/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1790 - accuracy: 0.5368\n",
            "Epoch 192/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1643 - accuracy: 0.5457\n",
            "Epoch 193/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1649 - accuracy: 0.5484\n",
            "Epoch 194/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1689 - accuracy: 0.5466\n",
            "Epoch 195/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1632 - accuracy: 0.5606\n",
            "Epoch 196/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1867 - accuracy: 0.5271\n",
            "Epoch 197/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1710 - accuracy: 0.5408\n",
            "Epoch 198/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1872 - accuracy: 0.5295\n",
            "Epoch 199/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1684 - accuracy: 0.5445\n",
            "Epoch 200/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1734 - accuracy: 0.5477\n",
            "Epoch 201/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1694 - accuracy: 0.5422\n",
            "Epoch 202/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1721 - accuracy: 0.5491\n",
            "Epoch 203/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1685 - accuracy: 0.5421\n",
            "Epoch 204/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1723 - accuracy: 0.5456\n",
            "Epoch 205/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1886 - accuracy: 0.5303\n",
            "Epoch 206/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1750 - accuracy: 0.5537\n",
            "Epoch 207/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1803 - accuracy: 0.5307\n",
            "Epoch 208/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1809 - accuracy: 0.5438\n",
            "Epoch 209/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1642 - accuracy: 0.5387\n",
            "Epoch 210/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1822 - accuracy: 0.5327\n",
            "Epoch 211/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1799 - accuracy: 0.5464\n",
            "Epoch 212/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1773 - accuracy: 0.5490\n",
            "Epoch 213/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1819 - accuracy: 0.5289\n",
            "Epoch 214/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1562 - accuracy: 0.5509\n",
            "Epoch 215/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1731 - accuracy: 0.5442\n",
            "Epoch 216/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1428 - accuracy: 0.5420\n",
            "Epoch 217/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1579 - accuracy: 0.5551\n",
            "Epoch 218/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1763 - accuracy: 0.5405\n",
            "Epoch 219/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1749 - accuracy: 0.5509\n",
            "Epoch 220/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1481 - accuracy: 0.5484\n",
            "Epoch 221/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1765 - accuracy: 0.5469\n",
            "Epoch 222/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1588 - accuracy: 0.5554\n",
            "Epoch 223/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1497 - accuracy: 0.5584\n",
            "Epoch 224/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1574 - accuracy: 0.5438\n",
            "Epoch 225/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1331 - accuracy: 0.5636\n",
            "Epoch 226/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1654 - accuracy: 0.5400\n",
            "Epoch 227/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1614 - accuracy: 0.5459\n",
            "Epoch 228/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1529 - accuracy: 0.5492\n",
            "Epoch 229/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1528 - accuracy: 0.5543\n",
            "Epoch 230/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1399 - accuracy: 0.5545\n",
            "Epoch 231/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1538 - accuracy: 0.5498\n",
            "Epoch 232/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1500 - accuracy: 0.5516\n",
            "Epoch 233/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1311 - accuracy: 0.5526\n",
            "Epoch 234/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1445 - accuracy: 0.5535\n",
            "Epoch 235/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1590 - accuracy: 0.5399\n",
            "Epoch 236/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1366 - accuracy: 0.5542\n",
            "Epoch 237/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1370 - accuracy: 0.5577\n",
            "Epoch 238/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1619 - accuracy: 0.5458\n",
            "Epoch 239/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1361 - accuracy: 0.5449\n",
            "Epoch 240/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1475 - accuracy: 0.5516\n",
            "Epoch 241/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1484 - accuracy: 0.5621\n",
            "Epoch 242/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1542 - accuracy: 0.5498\n",
            "Epoch 243/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1490 - accuracy: 0.5520\n",
            "Epoch 244/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1531 - accuracy: 0.5475\n",
            "Epoch 245/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1427 - accuracy: 0.5565\n",
            "Epoch 246/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1515 - accuracy: 0.5512\n",
            "Epoch 247/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1401 - accuracy: 0.5504\n",
            "Epoch 248/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1410 - accuracy: 0.5511\n",
            "Epoch 249/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1409 - accuracy: 0.5601\n",
            "Epoch 250/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1691 - accuracy: 0.5465\n",
            "Epoch 251/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1266 - accuracy: 0.5588\n",
            "Epoch 252/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1493 - accuracy: 0.5467\n",
            "Epoch 253/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1456 - accuracy: 0.5599\n",
            "Epoch 254/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1327 - accuracy: 0.5503\n",
            "Epoch 255/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1431 - accuracy: 0.5613\n",
            "Epoch 256/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1255 - accuracy: 0.5608\n",
            "Epoch 257/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1560 - accuracy: 0.5543\n",
            "Epoch 258/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1303 - accuracy: 0.5706\n",
            "Epoch 259/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1439 - accuracy: 0.5482\n",
            "Epoch 260/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1320 - accuracy: 0.5565\n",
            "Epoch 261/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1233 - accuracy: 0.5678\n",
            "Epoch 262/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1237 - accuracy: 0.5626\n",
            "Epoch 263/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1222 - accuracy: 0.5674\n",
            "Epoch 264/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1245 - accuracy: 0.5599\n",
            "Epoch 265/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1292 - accuracy: 0.5625\n",
            "Epoch 266/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1178 - accuracy: 0.5600\n",
            "Epoch 267/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1405 - accuracy: 0.5537\n",
            "Epoch 268/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1084 - accuracy: 0.5589\n",
            "Epoch 269/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1254 - accuracy: 0.5661\n",
            "Epoch 270/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1343 - accuracy: 0.5582\n",
            "Epoch 271/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1037 - accuracy: 0.5681\n",
            "Epoch 272/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1199 - accuracy: 0.5510\n",
            "Epoch 273/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1255 - accuracy: 0.5553\n",
            "Epoch 274/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1167 - accuracy: 0.5629\n",
            "Epoch 275/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1487 - accuracy: 0.5554\n",
            "Epoch 276/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1476 - accuracy: 0.5453\n",
            "Epoch 277/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1105 - accuracy: 0.5591\n",
            "Epoch 278/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1330 - accuracy: 0.5486\n",
            "Epoch 279/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1298 - accuracy: 0.5619\n",
            "Epoch 280/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1121 - accuracy: 0.5608\n",
            "Epoch 281/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1077 - accuracy: 0.5653\n",
            "Epoch 282/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1095 - accuracy: 0.5710\n",
            "Epoch 283/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1145 - accuracy: 0.5697\n",
            "Epoch 284/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1121 - accuracy: 0.5609\n",
            "Epoch 285/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1355 - accuracy: 0.5596\n",
            "Epoch 286/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1074 - accuracy: 0.5680\n",
            "Epoch 287/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1262 - accuracy: 0.5556\n",
            "Epoch 288/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1350 - accuracy: 0.5533\n",
            "Epoch 289/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1246 - accuracy: 0.5639\n",
            "Epoch 290/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1143 - accuracy: 0.5662\n",
            "Epoch 291/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1131 - accuracy: 0.5534\n",
            "Epoch 292/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1334 - accuracy: 0.5603\n",
            "Epoch 293/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1152 - accuracy: 0.5660\n",
            "Epoch 294/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0915 - accuracy: 0.5717\n",
            "Epoch 295/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1147 - accuracy: 0.5613\n",
            "Epoch 296/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1236 - accuracy: 0.5579\n",
            "Epoch 297/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1190 - accuracy: 0.5673\n",
            "Epoch 298/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0857 - accuracy: 0.5774\n",
            "Epoch 299/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1103 - accuracy: 0.5624\n",
            "Epoch 300/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1127 - accuracy: 0.5613\n",
            "Epoch 301/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1062 - accuracy: 0.5713\n",
            "Epoch 302/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1409 - accuracy: 0.5506\n",
            "Epoch 303/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1357 - accuracy: 0.5610\n",
            "Epoch 304/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1193 - accuracy: 0.5695\n",
            "Epoch 305/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0980 - accuracy: 0.5772\n",
            "Epoch 306/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0822 - accuracy: 0.5843\n",
            "Epoch 307/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0833 - accuracy: 0.5636\n",
            "Epoch 308/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1176 - accuracy: 0.5559\n",
            "Epoch 309/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1076 - accuracy: 0.5707\n",
            "Epoch 310/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1075 - accuracy: 0.5763\n",
            "Epoch 311/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0936 - accuracy: 0.5657\n",
            "Epoch 312/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0932 - accuracy: 0.5731\n",
            "Epoch 313/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1102 - accuracy: 0.5691\n",
            "Epoch 314/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0867 - accuracy: 0.5791\n",
            "Epoch 315/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1016 - accuracy: 0.5714\n",
            "Epoch 316/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1116 - accuracy: 0.5681\n",
            "Epoch 317/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0932 - accuracy: 0.5666\n",
            "Epoch 318/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0827 - accuracy: 0.5754\n",
            "Epoch 319/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0987 - accuracy: 0.5621\n",
            "Epoch 320/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0658 - accuracy: 0.5777\n",
            "Epoch 321/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0861 - accuracy: 0.5705\n",
            "Epoch 322/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1034 - accuracy: 0.5625\n",
            "Epoch 323/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0879 - accuracy: 0.5863\n",
            "Epoch 324/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1076 - accuracy: 0.5618\n",
            "Epoch 325/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0916 - accuracy: 0.5680\n",
            "Epoch 326/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1131 - accuracy: 0.5591\n",
            "Epoch 327/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0946 - accuracy: 0.5789\n",
            "Epoch 328/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1119 - accuracy: 0.5717\n",
            "Epoch 329/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0999 - accuracy: 0.5695\n",
            "Epoch 330/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0845 - accuracy: 0.5755\n",
            "Epoch 331/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0887 - accuracy: 0.5720\n",
            "Epoch 332/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0839 - accuracy: 0.5680\n",
            "Epoch 333/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1008 - accuracy: 0.5656\n",
            "Epoch 334/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0658 - accuracy: 0.5882\n",
            "Epoch 335/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0987 - accuracy: 0.5708\n",
            "Epoch 336/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0897 - accuracy: 0.5657\n",
            "Epoch 337/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0844 - accuracy: 0.5697\n",
            "Epoch 338/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0796 - accuracy: 0.5845\n",
            "Epoch 339/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0855 - accuracy: 0.5740\n",
            "Epoch 340/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0630 - accuracy: 0.5832\n",
            "Epoch 341/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0827 - accuracy: 0.5758\n",
            "Epoch 342/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0786 - accuracy: 0.5914\n",
            "Epoch 343/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0776 - accuracy: 0.5814\n",
            "Epoch 344/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0489 - accuracy: 0.5815\n",
            "Epoch 345/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0839 - accuracy: 0.5800\n",
            "Epoch 346/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0621 - accuracy: 0.5910\n",
            "Epoch 347/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0706 - accuracy: 0.5805\n",
            "Epoch 348/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0628 - accuracy: 0.5870\n",
            "Epoch 349/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0699 - accuracy: 0.5827\n",
            "Epoch 350/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0846 - accuracy: 0.5800\n",
            "Epoch 351/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0827 - accuracy: 0.5617\n",
            "Epoch 352/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0865 - accuracy: 0.5763\n",
            "Epoch 353/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0746 - accuracy: 0.5864\n",
            "Epoch 354/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0650 - accuracy: 0.5878\n",
            "Epoch 355/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0650 - accuracy: 0.5715\n",
            "Epoch 356/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0819 - accuracy: 0.5727\n",
            "Epoch 357/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0941 - accuracy: 0.5651\n",
            "Epoch 358/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0882 - accuracy: 0.5802\n",
            "Epoch 359/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0855 - accuracy: 0.5694\n",
            "Epoch 360/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0901 - accuracy: 0.5647\n",
            "Epoch 361/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0972 - accuracy: 0.5718\n",
            "Epoch 362/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0731 - accuracy: 0.5963\n",
            "Epoch 363/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0414 - accuracy: 0.5969\n",
            "Epoch 364/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0467 - accuracy: 0.5902\n",
            "Epoch 365/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0647 - accuracy: 0.5854\n",
            "Epoch 366/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0893 - accuracy: 0.5865\n",
            "Epoch 367/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0601 - accuracy: 0.5881\n",
            "Epoch 368/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.1047 - accuracy: 0.5660\n",
            "Epoch 369/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0493 - accuracy: 0.5844\n",
            "Epoch 370/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0594 - accuracy: 0.5892\n",
            "Epoch 371/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0764 - accuracy: 0.5769\n",
            "Epoch 372/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0682 - accuracy: 0.5947\n",
            "Epoch 373/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0819 - accuracy: 0.5704\n",
            "Epoch 374/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0585 - accuracy: 0.5858\n",
            "Epoch 375/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0740 - accuracy: 0.5806\n",
            "Epoch 376/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0708 - accuracy: 0.5838\n",
            "Epoch 377/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0784 - accuracy: 0.5811\n",
            "Epoch 378/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0658 - accuracy: 0.5890\n",
            "Epoch 379/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0655 - accuracy: 0.5876\n",
            "Epoch 380/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0535 - accuracy: 0.5903\n",
            "Epoch 381/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0707 - accuracy: 0.5762\n",
            "Epoch 382/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0761 - accuracy: 0.5688\n",
            "Epoch 383/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0873 - accuracy: 0.5718\n",
            "Epoch 384/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0753 - accuracy: 0.5709\n",
            "Epoch 385/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0651 - accuracy: 0.5793\n",
            "Epoch 386/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0739 - accuracy: 0.5809\n",
            "Epoch 387/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0562 - accuracy: 0.5857\n",
            "Epoch 388/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0767 - accuracy: 0.5736\n",
            "Epoch 389/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0935 - accuracy: 0.5686\n",
            "Epoch 390/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0411 - accuracy: 0.5862\n",
            "Epoch 391/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0449 - accuracy: 0.5868\n",
            "Epoch 392/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0538 - accuracy: 0.5827\n",
            "Epoch 393/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0781 - accuracy: 0.5714\n",
            "Epoch 394/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0493 - accuracy: 0.5883\n",
            "Epoch 395/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0466 - accuracy: 0.6017\n",
            "Epoch 396/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0554 - accuracy: 0.5847\n",
            "Epoch 397/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0726 - accuracy: 0.5872\n",
            "Epoch 398/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0438 - accuracy: 0.6051\n",
            "Epoch 399/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0524 - accuracy: 0.5926\n",
            "Epoch 400/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0430 - accuracy: 0.5811\n",
            "Epoch 401/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0385 - accuracy: 0.5923\n",
            "Epoch 402/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0539 - accuracy: 0.5866\n",
            "Epoch 403/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0726 - accuracy: 0.5797\n",
            "Epoch 404/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0625 - accuracy: 0.5832\n",
            "Epoch 405/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0365 - accuracy: 0.5962\n",
            "Epoch 406/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0750 - accuracy: 0.5900\n",
            "Epoch 407/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0566 - accuracy: 0.5877\n",
            "Epoch 408/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0381 - accuracy: 0.6015\n",
            "Epoch 409/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0742 - accuracy: 0.5799\n",
            "Epoch 410/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0391 - accuracy: 0.5880\n",
            "Epoch 411/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0610 - accuracy: 0.5899\n",
            "Epoch 412/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0480 - accuracy: 0.5973\n",
            "Epoch 413/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0765 - accuracy: 0.5798\n",
            "Epoch 414/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0453 - accuracy: 0.5908\n",
            "Epoch 415/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0806 - accuracy: 0.5791\n",
            "Epoch 416/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0718 - accuracy: 0.5798\n",
            "Epoch 417/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0627 - accuracy: 0.5824\n",
            "Epoch 418/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0450 - accuracy: 0.5861\n",
            "Epoch 419/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0766 - accuracy: 0.5823\n",
            "Epoch 420/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0646 - accuracy: 0.5720\n",
            "Epoch 421/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0333 - accuracy: 0.6017\n",
            "Epoch 422/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0689 - accuracy: 0.5755\n",
            "Epoch 423/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0375 - accuracy: 0.5966\n",
            "Epoch 424/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0379 - accuracy: 0.5801\n",
            "Epoch 425/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0465 - accuracy: 0.5992\n",
            "Epoch 426/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0398 - accuracy: 0.5850\n",
            "Epoch 427/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0210 - accuracy: 0.6027\n",
            "Epoch 428/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0348 - accuracy: 0.5930\n",
            "Epoch 429/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0333 - accuracy: 0.5967\n",
            "Epoch 430/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0312 - accuracy: 0.5970\n",
            "Epoch 431/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0576 - accuracy: 0.5851\n",
            "Epoch 432/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0397 - accuracy: 0.5934\n",
            "Epoch 433/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0379 - accuracy: 0.5922\n",
            "Epoch 434/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0397 - accuracy: 0.5862\n",
            "Epoch 435/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0565 - accuracy: 0.5769\n",
            "Epoch 436/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0498 - accuracy: 0.5923\n",
            "Epoch 437/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0408 - accuracy: 0.5987\n",
            "Epoch 438/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0391 - accuracy: 0.5994\n",
            "Epoch 439/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0342 - accuracy: 0.5872\n",
            "Epoch 440/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0818 - accuracy: 0.5731\n",
            "Epoch 441/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0364 - accuracy: 0.5939\n",
            "Epoch 442/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0470 - accuracy: 0.5880\n",
            "Epoch 443/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0458 - accuracy: 0.5941\n",
            "Epoch 444/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0489 - accuracy: 0.5784\n",
            "Epoch 445/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0275 - accuracy: 0.6006\n",
            "Epoch 446/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0376 - accuracy: 0.5903\n",
            "Epoch 447/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0587 - accuracy: 0.5903\n",
            "Epoch 448/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0456 - accuracy: 0.5919\n",
            "Epoch 449/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0274 - accuracy: 0.6000\n",
            "Epoch 450/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0672 - accuracy: 0.5815\n",
            "Epoch 451/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0368 - accuracy: 0.5857\n",
            "Epoch 452/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0653 - accuracy: 0.5912\n",
            "Epoch 453/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0202 - accuracy: 0.5903\n",
            "Epoch 454/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0381 - accuracy: 0.5849\n",
            "Epoch 455/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0442 - accuracy: 0.5883\n",
            "Epoch 456/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0347 - accuracy: 0.5850\n",
            "Epoch 457/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0344 - accuracy: 0.5929\n",
            "Epoch 458/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0250 - accuracy: 0.5966\n",
            "Epoch 459/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0342 - accuracy: 0.5909\n",
            "Epoch 460/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0314 - accuracy: 0.5972\n",
            "Epoch 461/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0342 - accuracy: 0.5843\n",
            "Epoch 462/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0570 - accuracy: 0.5875\n",
            "Epoch 463/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0204 - accuracy: 0.6114\n",
            "Epoch 464/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0168 - accuracy: 0.6057\n",
            "Epoch 465/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0419 - accuracy: 0.5912\n",
            "Epoch 466/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0634 - accuracy: 0.5826\n",
            "Epoch 467/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0461 - accuracy: 0.5789\n",
            "Epoch 468/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0221 - accuracy: 0.5958\n",
            "Epoch 469/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0315 - accuracy: 0.6006\n",
            "Epoch 470/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0700 - accuracy: 0.5866\n",
            "Epoch 471/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0402 - accuracy: 0.5774\n",
            "Epoch 472/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0559 - accuracy: 0.5827\n",
            "Epoch 473/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0199 - accuracy: 0.6036\n",
            "Epoch 474/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0380 - accuracy: 0.5879\n",
            "Epoch 475/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0443 - accuracy: 0.5917\n",
            "Epoch 476/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0147 - accuracy: 0.5956\n",
            "Epoch 477/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0326 - accuracy: 0.5927\n",
            "Epoch 478/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0539 - accuracy: 0.5776\n",
            "Epoch 479/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0424 - accuracy: 0.5984\n",
            "Epoch 480/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0132 - accuracy: 0.6017\n",
            "Epoch 481/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0299 - accuracy: 0.5956\n",
            "Epoch 482/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0314 - accuracy: 0.5966\n",
            "Epoch 483/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0466 - accuracy: 0.5955\n",
            "Epoch 484/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0362 - accuracy: 0.5986\n",
            "Epoch 485/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0192 - accuracy: 0.5990\n",
            "Epoch 486/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0066 - accuracy: 0.6037\n",
            "Epoch 487/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0204 - accuracy: 0.5985\n",
            "Epoch 488/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0287 - accuracy: 0.5942\n",
            "Epoch 489/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0416 - accuracy: 0.5907\n",
            "Epoch 490/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0089 - accuracy: 0.5975\n",
            "Epoch 491/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0368 - accuracy: 0.5908\n",
            "Epoch 492/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0208 - accuracy: 0.5939\n",
            "Epoch 493/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0057 - accuracy: 0.5999\n",
            "Epoch 494/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0321 - accuracy: 0.5964\n",
            "Epoch 495/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0237 - accuracy: 0.5991\n",
            "Epoch 496/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0281 - accuracy: 0.5993\n",
            "Epoch 497/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 0.9959 - accuracy: 0.6088\n",
            "Epoch 498/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0087 - accuracy: 0.6080\n",
            "Epoch 499/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0200 - accuracy: 0.5936\n",
            "Epoch 500/500\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.0291 - accuracy: 0.6006\n",
            "190/190 [==============================] - 1s 1ms/step - loss: 0.8351 - accuracy: 0.6951\n",
            "[0.8351219296455383, 0.6951078772544861]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPsjdqwZauQe"
      },
      "source": [
        "Question_Prob_Score = model_predict_questions.predict([[-5.6933826e-03, -7.1266070e-03, -6.0732388e-03, -3.7099647e-03,\n",
        "       -4.3845186e-03, -4.8060194e-03,  5.8907567e-04,  8.9565301e-03,\n",
        "       -2.7781818e-04,  8.1788274e-03, -1.1355451e-02,  1.2013778e-02,\n",
        "       -1.1618367e-02, -4.0041684e-04,  8.1981951e-03,  7.9985354e-03,\n",
        "       -9.8783765e-03, -1.2484683e-02,  1.6683192e-03,  8.3702430e-03,\n",
        "       -1.1477277e-02,  1.0705156e-02,  1.1443961e-02, -5.9133214e-03,\n",
        "        3.7552789e-03,  5.4123350e-03,  7.5901686e-03, -3.2808478e-03,\n",
        "       -8.0178697e-06,  1.1579112e-02, -1.1187740e-02, -5.4712980e-03,\n",
        "        6.8849633e-03,  1.5279922e-03, -8.7181134e-03,  9.3283039e-03,\n",
        "       -1.1335022e-02,  7.3210071e-03,  1.2493558e-04, -2.3488400e-03]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1ut9OqdqkBV",
        "outputId": "8166e428-63b1-4dce-862b-e05252bd34b1"
      },
      "source": [
        "Question_Prob_Score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.00454157, 0.06136133, 0.05578798, 0.7294206 , 0.1073968 ,\n",
              "        0.04149183]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKlmozSWthp3"
      },
      "source": [
        "Question_Prob_Score = Question_Prob_Score.tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82Zyj0d-YYhu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3f2c331-2e3f-44d2-fdf9-4cb0e6035106"
      },
      "source": [
        "max_index = []\n",
        "max_value = max(Question_Prob_Score)\n",
        "max_index = Question_Prob_Score.index(max_value)\n",
        "max_index"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mt7hF4NUbVEk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3516605b-c53f-4d50-b6fe-51829aca5578"
      },
      "source": [
        "encoder.inverse_transform([max_index])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Books'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lz0onHsZ9wnf",
        "outputId": "34f35d10-65ce-4a50-c12e-1f70a3690387"
      },
      "source": [
        "# from scipy import spatial\n",
        "# cos_distance = spatial.distance.cosine(question1, answer1)\n",
        "# cos_distance\n",
        "model_questions.wv.vectors.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1491, 40)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iSlHhT9IM_0L",
        "outputId": "2085e88a-b8ae-4365-da3c-e5050807a1a8"
      },
      "source": [
        "words=list(model_questions.wv.vocab)\n",
        "print(words)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['write', 'impact', 'book', 'plot', 'line', 'good', 'enough', 'premise', 'principal', 'concept', 'think', 'sibling', 'relationship', 'consider', 'author', 'person', 'skilled', 'describe', 'flow', 'exciting', 'part', 'story', 'people', 'angry', 'release', 'novel', 'martin', 'central', 'idea', '\\u200b\\u200bthe', 'free', 'imagination', 'feel', 'lot', 'chest', 'pain', '', 'readable', 'pace', 'series', 'feeling', 'one', 'threatening', 'villains', 'parts', 'like', 'kind', 'storyline', 'contain', 'pleasant', 'research', \"it's\", 'interesting', 'back', 'dialogue', 'sex', 'scene', 'way', 'adventure', 'message', 'reader', 'friend', 'based', 'rumor', 'real', 'opinion', 'give', 'us', 'istory', 'evil', 'many', 'chapters', 'missing', 'funny', 'contains', 'action', 'end', 'depressing', 'stuff', 'insight', 'gift', 'else', 'get', 'emotion', 'began', 'hot', 'hide', 'secret', 'bugs', 'registered', 'valid', 'point', 'probably', 'complicated', 'details', 'favorite', 'quality', 'style', 'world', 'building', 'love', 'appreciation', 'make', 'laugh', \"robinson's\", 'prose', 'word', 'objective', 'excitement', 'level', 'ending', 'say', 'long', 'thing', 'recommendations', 'would', 'readers', 'regarding', 'last', \"donalson's\", 'gap', 'fascinating', 'strength', 'described', 'best', 'experience', 'actually', 'better', 'sequel', 'words', 'heard', 'gregory', 'writing', 'historical', 'fiction', 'life', 'sentiment', 'perfect', 'effect', 'travel', 'flying', 'chapter', 'characterization', 'actors', 'character', 'development', 'read', 'half', 'hotel', 'payment', 'mystery', 'matter', 'unique', 'rate', 'greatest', 'short', 'find', 'scenes', 'evaluation', 'overall', 'unusual', 'attention', 'span', 'tell', 'art', 'twisted', 'satisfied', 'movie', 'second', 'personality', 'hero', 'beautiful', 'habit', 'means', 'detail', 'rewarding', 'talent', 'star', 'self', 'women', 'military', 'narrator', 'invoked', \"people's\", 'understanding', 'new', 'job', 'voice', 'hear', 'background', 'future', 'toward', 'brother', 'man', 'magical', 'impression', 'interaction', 'emotional', 'time', 'depth', 'great', 'hole', 'raw', 'reading', 'written', 'tracey', 'chevalier', 'knowledge', 'attraction', 'becomes', 'suffering', 'positive', 'review', 'balance', 'enjoyment', 'easy', 'infer', 'recommended', 'work', 'deep', 'tense', 'important', 'use', 'sense', 'relevant', 'rating', 'promised', 'land', 'grace', 'ogot', 'problem', 'car', 'mucho', 'considered', 'irregular', 'children', 'dou', 'yu', 'see', 'none', 'identify', 'tension', 'fresh', 'familiar', 'name', 'define', 'incredible', 'things', 'creations', 'causing', 'twist', 'foundation', 'advice', 'know', 'joke', 'family', 'empty', 'gareth', 'hyacinth', 'peprfect', 'pages', 'recipe', 'occur', 'grasp', 'progresses', 'general', 'pos', 'neg', 'books', 'leave', 'enjoyble', 'feelings', 'talk', 'odd', 'thomas', 'meaning', 'compared', 'original', 'verb', 'clear', 'serie', 'including', 'passion', 'reflected', 'pra', 'pug', 'much', 'cost', 'christie', 'seen', 'novels', 'take', 'role', 'perspective', 'main', 'character,', 'according', 'reviewer,', 'special', 'terms', 'solve', 'whole', 'amusing', 'satisfactory', 'writer', 'come', 'benefit', 'purpose', 'bad', 'dirty', 'fight', 'moment', 'dull', 'inspirational', 'redundant', 'five', 'element', 'available', 'james', 'mean', 'choice', 'imagery', 'want', 'twice', 'intense', 'towards', 'education', 'learn', 'different', 'first', 'three', 'forme', 'problems', 'happy', 'firstbook', 'conversational', \"what's\", 'likeable', 'awarded', 'inspires', 'concern', 'hemingway', 'achieve', 'violence', 'stories', 'ulterior', 'motives', 'agatha', \"christie's\", 'beach', 'start', \"dog's\", 'eye', 'banter', 'value', 'reality', 'something', 'terrifying', 'cathy', 'glass', 'completed', 'synopsis', 'specific', 'places', 'anything', 'relatable', 'heroine', 'ability', 'mantel', 'thi', 'fantasy', 'youth', 'makes', \"how's\", 'correct', 'dialogues', 'fact', 'piece', \"book's\", 'perceived', 'excellent', 'deal', 'parent', 'child', 'keys', 'keyboard', 'product', 'cover', 'well', 'speaker', 'speed', 'sound', 'price', 'camera', 'poor', 'feature', 'router', 'button', 'press', 'phome', 'comes', 'charger', 'unit', 'set', 'device', 'advanced', 'image', 'result', 'control', 'tv', 'volume', 'interface', 'signal', 'lightweight', 'bottle', 'bass', 'difference', 'images', 'headphone', 'connection', 'card', 'sizes', 'lens', 'system', 'fast', 'box', 'setting', 'base', 'inscription', 'process', 'capacity', 'clip', 'machine', 'size', 'ear', 'finger', 'provide', 'storage', 'padding', 'hardware', 'tablet', 'complaint', 'guys', 'battery', 'fm', 'reception', 'extra', 'display', 'instruction', 'raise', 'music', 'big', 'resolution', 'screen', 'power', 'supply', 'sharpness', 'binoculars', 'remote', 'grip', 'material', 'text', 'prefer', 'design', 'finish', 'simple', 'drawer', 'full', 'headphones', 'key', 'potatoes', 'bite', 'crispy', 'transfer', 'happend', 'whit', 'cable', 'lcd', 'solid', 'performance', 'intuitive', 'auto', 'focus', 'drive', 'city', 'stiff', 'color', '3d', 'rendering', 'pads', 'extremely', 'comfortable', 'winner', 'bezel', 'light', 'bathroom', 'impressions', 'connector', 'installation', 'company', 'driver', 'safety', 'texture', 'fantastic', 'stand', 'space', 'lenght', 'install', 'mini', 'tripod', 'specifications', 'laptop', 'angle', 'compartment', 'internal', 'typing', 'strong', 'zipper', 'setup', 'hard', 'nice', 'glove', 'pockets', 'importance', 'nook', 'going', 'loud', 'modem', 'colors', 'white', 'cables', 'resistant', 'return', 'policy', 'specs', 'build', 'earphone', 'push', 'acceleration', 'dose', 'fine', 'bubble', 'disc', 'mic', 'heating', 'solved', 'notebook', 'computer', 'happened', 'wins', 'game', 'audio', 'optics', 'receptivity', 'touch', 'packaging', 'include', 'complete', 'kit', 'playing', 'video', 'pictures', 'sharp', 'thick', 'bag', 'usb', 'noise', 'heavy', 'processor', 'amount', 'brittle', 'plastic', 'done', 'stands', 'leather', 'item', 'small', 'pen', 'weight', 'common', 'information', 'support', 'zoom', 'ease', 'reliable', 'offered', 'belkin', 'manual', 'active', 'form', 'factor', 'deepest', 'function', 'affect', 'move', 'appearance', 'pocket', 'selection', 'products', 'bought', 'amazon', 'touchpad', 'pan', 'send', 'package', 'place', 'sub', 'helpless', 'collection', 'film', 'look', 'adapter', 'proportional', 'shipping', 'configure', 'ring', 'smooth', 'features', 'monitor', 'happens', 'ports', 'plug', 'artistic', 'shipment', 'graphics', 'buy', 'devices', 'shape', 'high', 'absolutely', 'status', 'iii', 'v', 'microphone', 'designs', 'house', 'huge', 'profile', 'room', 'relative', 'configuration', 'song', 'goo', 'highs', 'customer', 'readiness', 'head', 'player', 'model', 'sides', 'respect', 'became', 'flash', 'speakers', 'warmer', 'helpful', 'direction', 'technical', 'generic', 'service', 'clasp', \"don't\", 'elastic', 'band', 'navigation', 'cheapest', 'operation', 'expensive', 'map', 'amazing', 'instructions', 'results', 'mountain', 'live', 'expectation', 'structured', 'works', 'newest', 'technology', 'seem', 'reasonable', 'operate', 'decent', 'strange', 'holding', 'low', 'mentioned', 'photo', 'wish', 'apples', 'multiple', 'trying', 'options', 'menu', 'cell', 'phone', 'mouse', 'plantronics', 'output', 'instruments', 'charge', 'option', 'airflow', 'coming', 'inches', 'canon', 't1i', 'lenses', 'shoes', 'receiver', 'customers', 'helpfull', 'could', 'reputation', 'memory', 'wireless', 'accurate', 'slightly', 'complaints', 'mount', 'compare', 'using', 'z-680', 'agent', 'kernel', 'coffee', 'aftertaste', 'taste', 'popcorn', 'caramel', 'tasty', 'cracker', 'o', 'protein', 'bar', 'meals', 'bud', 'rather', 'crackers', 'larger', 'sauce', 'satisfying', 'serving', 'skin', 'textured', 'fruit', 'bread', 'noodle', 'sugar', 'content', 'combination', 'tooth', 'drink', 'natural', 'chocolate', 'meal', 'snack', 'food', 'observe', 'granola', 'sweet', 'smoke', 'dishes', 'cup', 'cookies', 'ate', 'event', 'ingredients', 'biggest', 'bean', \"bar's\", 'caffeine', 'used', 'soup', 'chicken', 'noodles', 'difficult', 'ingredient', 'black', 'licorice', 'taste,', 'quantity', 'serve', 'minerals', 'vitamins', 'present', 'fiber', 'preparation', 'water', 'pleasing', 'oat', 'sweetness', 'cereal', 'flavor', 'packet', 'oatmeal', 'pasta', 'firm', 'cups', 'calorie', 'blanket', 'plain', 'aroma', 'crunchy', 'calories', 'almonds', 'consistency', 'portion', 'appetizer', 'flavoured', 'lollipops', 'pack', 'ones', 'every', 'flavour', 'kinds', 'crunch', 'variety', 'open', 'delicious', 'yogurt', 'coconut', 'chips', 'fat', 'almond', 'tazo', 'teas', 'blend', 'index', 'clean', 'salt', 'meat', 'tender', 'tea', 'gloria', \"jean''s\", 'bigger', 'prepare', 'cream', 'container', 'kick', 'hulled', 'seeds', 'nutrients', 'eating', 'made', 'healthy', 'consumers', 'restaurant', 'offers', 'meal,', 'mainly', 'drinks', 'sometimes', 'snacks', 'ginger', 'cataloged', 'body', 'majority', 'seed', 'bitter', 'germany', 'fair', 'macaroni', 'cheese', 'corn', 'syrup', 'formula', 'list', 'weak', 'inside', 'tomatoes', 'nuts', 'spicy', 'sensitive', 'donuts', 'distinctive', 'honey', 'liking', 'possibility', 'enjoyable', 'reason', 'nutsas', 'dark', 'carbs', 'money', 'chocolates', 'cold', 'count', 'hope', 'put', 'waiting', 'prodacts', 'access', 'kid', 'able', 'milk', 'preference', 'atmosphere', 'terrific', 'fabric', 'diabetic', 'patients', 'consume', 'recipes', 'less', 'others', 'candy', 'mint', 'version', 'grind', 'peculiar', 'mouth', 'excess', 'dinner', 'brown', 'rice', 'health', 'cake', 'burn', 'eat', 'reach', 'breackfast', 'issue', 'served', 'order', 'blends', 'medicinal', 'excelent', 'costume', 'criticism', 'deserves', 'christ', 'mel', 'gibson', 'soo', 'confusing', 'watch', 'number', 'show', 'really', 'plenty', 'flaws', 'language', 'production', 'animation', 'commentary', 'rest', 'cast', 'picture', 'episode', 'match', 'actor', 'episodes', 'effects', 'case', 'interview', 'looks', 'village', 'farmer', 'paint', 'flawed', 'filmso', 'enjoy', 'moral', 'weekend', 'single', 'chemistry', 'adventures', 'superbit', 'pop', 'characters', 'views', 'aspect', 'among', 'cinematography', 'making', 'husband', 'standard', 'edition', 'editing', 'scenery', 'characterized', 'phenomenal', 'powerful', 'scary', 'appropriate', 'tone', 'christmas', 'genre', 'storylines', 'today', 'anaconda', 'print', 'th', 'conflicting', 'artists', 'medication', 'cause', 'fun', 'popular', 'inmersive', 'adorable', 'son', 'pieces', 'direct', 'save', 'moments', 'dialog', 'types', 'score', 'cool', 'track', 'happen', 'beating', 'actions', 'credible', 'humor', 'plays', 'yo', 'dvd', 'acting', 'visual', 'favourite', 'act', 'rude', 'heart', 'suit', 'tastes', 'annoying', 'oh', 'expend', 'realistic', 'faithful', 'bible', 'shoot', 'worth', '.', 'brutality', 'unrelenting', 'bonus', 'parks', 'two', 'karate', 'champions', 'kenya', 'uganda', 'become', 'brilliant', 'history', 'eternal', '3-d', 'represent', 'documentary', 'themes', 'timing', 'resume', 'along', 'ordinary', 'audience', \"jones'\", 'fully', 'charged', \"spielberg's\", 'dinosaurs', 'ridley', \"scott's\", 'aliens', 'rubbish', 'stunts', 'strengths', 'weaknesses', 'relation', 'european', 'cinema', 'movies', 'judgement', 'wife', 'trailer', 'play', 'villain', 'screenplay', 'cowboy', 'usefull', 'childhood', 'ghostbusters', 'expressions', 'face', 'wonderful', 'double', 'quipo', 'complex', 'gives', 'entertainment', \"maria's\", 'artifacts', 'type', 'old', 'catching', 'sequence', 'okay', 'shocking', 'soundtrack', 'tenebrae', 'directed', 'dario', 'argento', \"'the\", \"avengers'\", 'youngsters', 'director', '\"passion', 'christ\"', 'lighting', 'wrote', 'took', 'jeff', 'barbra', \"movie's\", 'pretty', 'understand', 'remake', 'characterizes', 'terror', 'broadcast', 'true', 'smart', 'truth', 'reviewed', 'said', 'lacking', 'properties', 'usually', 'also', 'soft', 'lesson', 'times', 'embodied', 'theme', 'values', 'right', 'side', 'estimate', 'classic', 'reunion', 'horse', 'taco', 'dish', 'kitchen', 'effectiveness', 'table', 'everything', 'offer', 'greek', 'sushi', 'dessert', 'day', 'neat', 'presentation', 'tolerable', 'seafood', 'economical', 'brunch', 'entree', 'tacos', 'date', 'environment', 'evening', 'thai', 'moist', 'pizza', 'seat', 'crepe', 'vegan', 'waiter', 'staff', 'catchy', 'cooked', 'authentic', 'horrible', 'disappointing', 'burger', 'beer', 'lunch', 'filling', 'american', 'breakfast', 'prices', 'balanced', 'top', 'notch', 'cleanliness', 'hostess', 'friendly', \"waiter's\", 'help', 'tonight', 'buying', 'eggs', 'poutine', 'recommendation', 'flavourful', 'dim', 'sum', 'egg', 'perfectly', 'poach', 'curry', 'condition', 'prefer,', 'vanilla', 'broth', 'state', 'plate', 'quick', 'steakhouse', 'ramen', 'oyster', 'salad', 'per', 'server', 'fill', 'foods', 'pork', 'spot', 'bowl', 'site', 'tasteful', 'cheap', 'tummy', 'trek', 'warm', 'welcome,', 'attentive', 'pancake', 'together', 'fry', 'provided', 'french', 'toast', 'vibe', 'unpleasant', 'steak', 'maximum', 'busy', 'tables', 'found', 'complimentary', 'relaxing', 'disappointment', 'ready', 'highly', 'exelent', 'calamari', 'baked', 'fish', 'everyone', 'waiters', 'affordable', 'known', 'comfort', 'paying', 'bills', 'little', 'removal', 'needed', 'wine', 'ambience', 'daily', 'shrimp', 'town', 'working', 'chinatown', 'vibes', 'suggestion', 'improve', 'largest', 'breads', 'burgers', 'night', 'weather', 'chashu', 'layout', 'thel', 'beverages', 'higher', 'lower', 'expected', 'standards', 'hamburgers', 'venue', 'bit', 'kilograms', 'cart', 'waffles', 'dumplings', 'lines', 'sandwich', 'terrible', 'tiny', 'bartender', 'efficient', 'lights', 'warmth', 'always', 'location', 'juice', 'complain', 'rancher', 'portions', 'crust', 'jerk', 'perfecto', 'share', 'servers', 'plane', 'cocktail', 'wait', 'normal', 'average', 'various', 'cocktails', 'pub', 'flavors', 'recommend', 'salads', 'antipesto', 'locate', 'necessary', 'childcare', 'reviews', 'competitive', 'meeting', 'additional', 'pay', 'plates', 'fixed', 'frites', 'generous', 'large', 'stink', 'california', 'beers', 'prince', 'late', 'snacking', 'ordering', 'west', 'indian', 'restaurants', 'days', 'reserving', 'messy', 'parking', 'view', 'behave', 'buffet', 'decor', 'check', 'smell', 'bed', 'shower', 'pound', 'concierge', 'rank', 'decency', 'front', 'desk', 'hour', 'stay', 'tourist', 'another', 'accommodating', 'located', 'walk', 'near', 'boutique', 'alcatraz', 'motel', 'behaviour', 'next', 'continental', 'sized', 'san', 'francisco', 'sink', 'rooms', 'treatment', 'fee', 'office', 'public', 'transportation', 'optimal', 'neighborhood', 'street', 'pool', 'wharf', 'class', 'hotels', 'internet', 'member', 'doctors', 'hospital', 'lobby', 'sheets', 'classificated', 'agronaut', 'transport', 'accommodation', 'attent', 'tasting', 'morning', 'close', 'stop', 'bath', 'kra', 'offices', 'spa', 'refrigerator', 'valet', 'spacious', 'sold', 'shopping', 'carpet', 'conditions', 'quiet', 'hospitable', 'wifi', 'area', 'search', 'online', 'amenity', \"bartender's\", 'bus', 'upgrade', 'king', 'go', 'downtown', 'elevator', 'pass', 'trained', 'situated', 'address', 'interior', 'decorate', 'walked', 'around', 'receptionist', 'treat', 'louder', 'outside', 'sea', 'facilities', 'fabulous', 'knowledgeable', 'trip', 'norfolk', 'sites', 'bathrooms', 'shores', 'friends', 'india', 'security', 'particularly', 'cookie', 'cafe', 'professional', 'lovely', 'safe', 'suite', 'daughter', 'stayed', 'structure', 'fix', 'uncomfortable', 'extensions', 'bedroom', 'york', 'floor', 'diani', 'call', 'memorable', 'situation', 'traffic', 'smallest', 'expect', 'union', 'square', 'awesome', 'bottled', 'checkout']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBVQZik1Vv2b",
        "outputId": "eb8a7e8b-dfe0-4ebe-fbae-7f058dcad08c"
      },
      "source": [
        "model_answers.wv.vectors.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(446, 40)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nR_SGvV5aHY0",
        "outputId": "f562480a-5f5c-46bd-b582-8e589512f086"
      },
      "source": [
        "words=list(model_answers.wv.vocab)\n",
        "print(words)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['The writing is excellent', 'this story is simply fantastic', 'Everything about the story was interesting and educational', 'The research necessary to write this book is impressive', 'beautiful story', 'good', 'this book tore a hole through my heart', 'The book was a real reflection on the goodness in some people and the evil in others', 'amazing', 'The story is a mystery novel', 'It is an excellent read', 'I loved this book', 'this one is just as good', 'I loved it', 'This series was great', 'This book was terrible', 'the sex is surprisingly bland', 'This book is absurdly bad', 'An absolutely fantastic book', 'The research to write this book was amazing', 'This series is wonderful', 'EXCELLENT', 'The plot is very good', 'This is a very good book', 'The premise was interesting', 'This was a really good story', 'incredible', 'great chemistry', 'the end was stupid', 'the characters are well drawn', 'The writing is horrible', 'This book was really good and surprisingly deep', 'It was so good', 'This book is amazing', 'Harry Potter', 'The story itself is rather dull in retrospect', 'The advice is very practical and accurate!You', 'They are just wonderful', 'the book leaves you satisfied', 'story is remarkable and inspiring', 'I read this book', 'This book is so well written', 'have', 'horrible', 'basically', 'The story is amazing', 'the price is amazing', '4 and 5 Star reviews', 'the sound quality is great', 'The TV is incredibly', 'Sound quality is awesome', 'This camera is stacked with features and takes fantastic pictures', 'These headphones are very nice', 'They have exceptional sound quality and decent sound isolation', 'The image quality is amazing at this price point', 'The size is great', 'This router is just plain awesome', 'These speakers feel good and sound amazing', 'This case also has plenty padding', 'their hardware is good', 'The camera is awesome', 'the design is elegant', 'sound is decent', 'the set of headphones is extremely comfortable', 'superb LCD', 'the materials look durable', 'decent', 'the screen is tiny', 'The sound is rich , deep and bassy when needed', 'The installation is not easy but you will ace it', 'I especially like the fact that the image is good from almost any angle', 'The sound is loud', 'I just love the quality if their products', 'Image quality is superb', 'the sound on the speaker was really low', 'Works perfectly', 'This webcam was recommended to me by a friend', 'the sound is not good', 'This thing is awesome', 'The screen is rather nice', 'This kit was complete', 'This unit is very nice', 'the sound is quite amazing', 'This tripod is nice and cheap', 'Video quality is exceedingly poor', 'The sound quality is just alright on these', 'bass is solid and powerful', 'comfortable', 'the connector was VERY tight', 'the keyboard is very easy to use', 'subwoofer looks great next to the entertainment center', '32 GB', 'low cable noise', 'Image quality is good', 'excellent', 'Monitor is very thin', 'pretty good', 'The sound quality was amazing', 'The instructions are clear and easy to follow', 'small', 'Great', 'The color on these is just gorgeous and the picture is nice and sharp', 'This camera is fantastic', 'THE PRICE IS REASONABLE', 'This is the fastest drive I have ever installed', 'HDMI', 'This mount is great', '#NAME?', 'This popcorn is tasty and sweet', \"It 's a unique flavor\", 'These bars are quite tasty and healthy', 'This product was just alright for me', 'This coffee is nice', 'The coffee is wonderful', 'Great taste and refreshment', 'This coffee is delicious and organic', 'The texture of the twists is firm', 'These chocolates were quite delicious', 'easy boxed meal to cook every now and then', 'The texture reminded me a little bit of the original Power Bar', 'There is no added sugar', 'I always want to have a cup of tea and this tea is delicious', 'the mixture granola is very tasty', 'great', 'This soup is moderately spicy', 'natural organic', 'the taste is not overly strong', 'the smaller size makes it a more sensible serving', 'slightly more fiber', 'been', 'This cereal not only tastes great but it does not get soggy', 'The taste is honey', '120 calories', 'My first sip impression was that of mango with an odd but not unpleasant underlying aromatic flavor', 'The taste is very pleasing', 'natural', 'This coffee smelled great', 'These cereals are all too sweet', 'caramel treats are quite tasty', \"I would n't mind if calories were lower\", 'This stuff taste great', 'The texture was great', 'The taste was extremely sweet', 'It has a nasty taste and an unpleasant aftertaste', 'The consistency and texture were perfect', 'This coffee is fairly bold', 'The coffee is fair', 'the texture is light and crispy', 'this sauce definitely exceeded my expectations!I', 'The chocolate flavor is full and rich', 'The sweetness is about right', 'looking noodles are light and tasty', \"the taste is n't bad\", 'The almonds were sweet and fresh', 'The texture of these cookies is odd', 'the flavor jumps in as an aftertaste and is use right', 'This drink is nice and refreshing', 'The taste is not bad', 'The packaging states that it has no refined sugar', 'I imagined it would taste very pleasantly enjoyable', 'apple , cinnamon and oats', 'This gourmet coffee has a delicious aroma', 'These are bite sized', 'It tastes great', 'The texture is nice crunchy', 'very good', 'little sugar', 'Good taste', 'The coffee smells great', 'Honey is always so tailored from nature', 'This', 'Has a nice unique nutty taste', 'This coffee is so smooth', 'delicious', 'the cakes are moist and delicious', 'lovely', 'is brilliant', 'The animation in this movie is just beautiful and sometimes photorealistic', 'The idea sounds good', 'This movie really is incredible', 'The music and performing were wonderful', 'The music was superb', 'perfect', 'The characters are real', 'The series was great', 'was an awesome movie to watch', 'the picture is awful', 'The characters are complex and flawed', 'The movie is sad and tragic', 'picture quality is great', 'the', 'these episodes look simply amazing', 'DVD', 'The sound also got a boost from the original mono track to stero', 'The story is captivating and definitely comes to life with all the cg', 'The movie was captivating and entertaining', 'The animation is amazing', 'the actors are brilliant', 'Great movie', 'This film is wonderful', 'This film is just right', 'the story and acting were both superb', 'A very brutal and terrifyingly emotional piece', 'audio was GREAT', 'characters are cute and likeable', 'The visuals are incredible and beautiful', 'the cinematography is breathtaking', 'great actors', 'This movie was entertaining', 'The chemistry between the two leads was believable', 'quality', 'great films', 'This series is great', 'The plot was weak', 'The picture is fabulous', 'The characters are believable , displaying their flaws as well as their strengths', 'The show is excellent', \"I could n't believe how good this looked\", 'The actors that were cast in this film are fantastic', 'The movie is dark', 'the movie was boring', 'This lovely little movie is so charming and so sweet', 'The music is wonderful', 'this movie is suitable for children', 'The first movie was very dull and kinda boring', 'the score and songs by Randy Newman are just great', 'wonderful', 'The characters have grown and changed', 'This movie is HORRIBLE', 'Special effects are awesome and even the plot is decent but this movie is clearly missing something', 'The video , audio and special effects are excellent', 'Good movie and the action is nonstop', 'This movie was terrible', 'the colors are great', '$ 11', 'The food was good', 'cityLove', 'The food was bland and un exciting', 'Great seafood', 'The menu is simple', 'the food is good', 'here', 'the food not so much', 'Definitely some unique and different foods on the menu', 'The cutest place for brunch in Toronto', 'terrible service', 'my favourite dish of the night was the liver and onions', 'The staff were great', 'Service is good', 'Great place', 'GREAT portions and prices', 'The food was amazing', 'the best pizza in Toronto', 'decent sized portions', 'Great Crepe Place', 'absolutely shocked by the horrible service', 'BEST STAFF', 'Sushi was pretty good and fresh', 'Fantastic steak', 'the Mexican food is good', 'Food was great', 'One of the best Fish and Chips place in Toronto', 'The broth was good', 'food was good', 'food is really good', 'Atmosphere is nice and laid back', 'friendly service', 'The service was exceptional and the food was out of this world', \"Best crepe I 've ever had in Toronto\", 'the food however was not as amazing as I expected', 'the food was delicious', 'Excellent service', 'great food', 'enjoyed', 'serving notable flavours', 'Great ambience but busy because it is popular', 'The service was only ok', 'I love crepes', 'was good', 'The pricing is great', 'Best sushi restaurant ever', 'Service was also great', 'I love the food', 'Service was friendly and efficient', 'Amazing food', 'The whole experience was perfect', 'Desserts are extremely inventive', 'Great customer service and friendly staff', 'serviceThe food was very declious and yummy', 'The service is friendly and quick', 'Good food', 'would recommend to everyone', 'really good', 'Best sushi ever', 'Both were delicious', 'Best crepe I ever had', 'the staff was very pleasant', 'Good quality food and well priced', 'The service was great', 'wonderful experience', 'Great and fast customer service', 'The continental breakfast was nice', 'The bar is really nice', 'hottest showers I have encountered anywhere', 'The staff was rude and unaccommodating', 'Food is expensive at the hotel', 'the service was fantastic', 'Very bad experience', 'nice breakfast buffet', 'Desk staff ranged from surly to very helpful over the three days', 'attentive staff', 'Front desk staff were friendly and attentive', 'lovely free coffee', 'Great Location', 'European feel boutique hotel with excellent service', 'closet!!!!The staff was amazing', 'The continental breakfast is nice', 'The free parking was a huge plus', 'staff were delightful', 'Staff was friendly and very helpfull', 'Super comfy bed', 'The reception staff where very polite and helpful', 'We had a good experience with the hotel overall', 'The service is spectacular', 'relaxed service', 'This was my first experience using travelocity and decided to take a chance and book a little getaway for the Labor Day weekend', 'Anyone would have a wonderful stay here', 'Parking is very convenient in their own garage', 'This is the worst hotel I have stayed in', 'The location is great', 'Small but nice bathroom', 'Central location', 'service was excellent', 'Constant noise all day and night', 'Room service is quick and very good', 'We had a wonderful experience', 'The people there were very friendly', 'Good continental breakfast', 'The wireless Internet service was a little weak', 'loved the afternoon wine', 'The pool area was nice', 'Breakfast was included and as other have said there was a good selection', 'Employees were very pleasant and helpful', 'The service at the hotel was below average on the verge of terrible', 'elegant lobby', 'Service was outstanding', 'fantastic service', 'The staff was top rate', 'enjoyable experience', 'Wine reception is great at 5:30pm', 'Concierge very knowledgeable', 'The staff was friendly and professional', 'close to chinatown', 'The staff was friendly enough but not very helpful', 'spa sounded nice', 'the Hotel staff was friendly and always helpful', 'The front desk staff was extremely rude', 'The bathroom was huge and was very clean', 'The bathroom was small', 'The service is fabulous', 'The carpet was really dirty', 'The service was bad', 'The staff were helpful', 'Staff was attentive and accomodating', 'The staff is very pleasant and cheerful', 'Parking was easy in the underground parking garage', 'the staff is exeptional', 'helpful staff', 'The staff is personable , extremely helpful , and appropriately personal', 'great spot', 'Top quality and fabulous staff', 'The concierges were great', 'Reception staff were friendly and helpful', 'room service was great and the food was so good', 'it!The hotel was cheap and fabulous at the same time', 'free parking', \"It 's an older building that 's been nicely renovated\", 'The kids loved the pool', 'Extremely elegant hotel', 'Horrible service', 'The service from all staff was superb', 'The staff were quite unfriendly', 'The service was very helpful and nice too', 'Fantastic hotel', 'The bathroom was very nice', 'Nice view of the city', 'Rooms were spacious enough', 'view was perfect', 'The bed was fine', 'The wine in the afternoons is a nice touch', 'The service is exquisite', 'The bed was awful', 'excellent service', 'The lobby is Great', 'Huge bathroom', 'The staff is exceptional', 'The front desk staff was very nice', 'very nice hotel', 'Staff is excellent', 'The staff were lovely', 'They staff was fabulous', 'free parking and clean', 'The bathroom had a nice line of complimentary toiletries', 'The staff are very helpul and courteous at all times', 'The staff is horrible', 'The bathroom was quite large with nice bath products', 'The staff was knowledgeable and helpful', 'excellent value for money', 'The front desk staff were great', 'It would have been good to have more variety to choose', 'breakfast buffet great', 'The staff was very attractive and very helpful', 'The service was poor', 'concierge was a great help', 'all the Staff who do a great job in making you feel welcome', 'Great value for money', 'outstanding service', 'nice', 'This hotel is overpriced and definitely not the most pleasant place to stay', 'accommodating staff', 'the bathroom was great', 'everything else was good', 'The staff were very helpful and informative', 'The decor was fun though', 'The staff was extremely helpful and responsive', 'The breakfast buffet served downstairs in the morning was very good too', 'great service', 'Beautiful views of the city', 'The bed and bedding were wonderful', 'Excellent value for money', 'fabulous staff', 'appealing and interesting decor', 'the view was fabulous', 'delightful and incredibly helpful staff', 'Their staff was rude', 'Cable car stop right outside the hotel entrance', 'Very good service', 'Excellent service and stay', 'efficient service and steaks', 'Nice breakfast bar , and evening wine reception', 'The staff is wonderful and I always find it easy to relax and unwind in my room', 'the staff was awesome', 'The room was extremely small', 'the horrible service', 'the very kind staff', 'The wine reception was nice']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IHRJC_XdIpbV",
        "outputId": "1f57f252-6fae-483a-8e1d-bc51158d2cfb"
      },
      "source": [
        "model_answers.most_similar(['small'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('delightful and incredibly helpful staff', 0.44622084498405457),\n",
              " ('I loved it', 0.4434046447277069),\n",
              " ('This', 0.4351232647895813),\n",
              " ('This camera is fantastic', 0.40405070781707764),\n",
              " ('Parking is very convenient in their own garage', 0.40143734216690063),\n",
              " ('Good taste', 0.37378042936325073),\n",
              " ('The decor was fun though', 0.3488338589668274),\n",
              " ('GREAT portions and prices', 0.34237539768218994),\n",
              " ('They are just wonderful', 0.32423657178878784),\n",
              " ('The lobby is Great', 0.30817711353302)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0drzFPUVIyIC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}